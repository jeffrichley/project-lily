petal: "1"
name: "Data Processing Workflow"
description: "Example workflow for processing CSV data"

params:
  input_file:
    type: "str"
    required: true
    help: "Input CSV file path"
  output_format:
    type: "str"
    default: "json"
    help: "Output format (json, csv, xml)"
  batch_size:
    type: "int"
    default: 1000
    help: "Number of records to process in each batch"

vars:
  output_file: "output/processed_data.{{ params.output_format }}"
  temp_dir: "temp/data_processing"

steps:
  - id: "validate_input"
    uses: "shell"
    with_:
      command: "test -f {{ params.input_file }} && echo 'Input file exists' || exit 1"
    outputs:
      validation:
        type: "str"
        path: "output/validation.txt"

  - id: "process_data"
    uses: "shell"
    needs: ["validate_input"]
    env:
      INPUT_FILE: "{{ params.input_file }}"
      OUTPUT_FILE: "{{ vars.output_file }}"
      BATCH_SIZE: "{{ params.batch_size }}"
    with_:
      command: |
        echo "Processing {{ params.input_file }} in batches of {{ params.batch_size }}"
        echo "Output will be saved to {{ vars.output_file }}"
        # Simulate data processing
        echo "Data processing completed" > {{ vars.output_file }}
    outputs:
      processed_data:
        type: "str"
        path: "{{ vars.output_file }}"

  - id: "generate_report"
    uses: "shell"
    needs: ["process_data"]
    with_:
      command: "echo 'Processing report generated at $(date)' > output/report.txt"
    outputs:
      report:
        type: "str"
        path: "output/report.txt"

outputs:
  processed_data:
    from: "processed_data"
    type: "str"
  report:
    from: "report"
    type: "str"
